sleepers <- data.frame(Minutes = c(5, 7, 10, 12, 14, 16, 18, 20, 21, 23, 25, 27, 28, 30, 32, 33, 35, 37, 39, 41, 42, 44, 46, 48), Asleep = c(2, 2, 3, 4, 4, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8))
knitr::kable(sleepers)
setwd("~/Dropbox/GitHub/Math438Fall2021/Chapter2")
### Read in the raw data to be fit
data <- read.csv("Observations.csv", header = T)
#### Plot the data ---------
### Let's explore the data visually
plot(data, type="l")
### Data seem to be exponential of some kind
### Try plotting log y
plot(data,type="l", log="y")
### Log y didn't fix it. Try log x instead.
plot(data,type="l", log="x")
### Log x and log y didn't work. Try log-log instead.
plot(data,type="l", log="xy")
### What model does this suggest in the untransformed variables x,y?
### Log y didn't fix it. Try log x instead.
plot(data,type="l", log="x")
#### A slightly different model ----
### We can also fit this using a altered "link" function in glm, try it!
summary(m2 <- glm(Observation ~ log(Input), data, family = gaussian(link = "log")))
### Now check out the diagnostics
plot(m4)
set.seed(julian(Sys.Date()))
x <- runif(100,0,10)
y <- 4 + (x-2)^2 + runif(100,-1,1)*0.5*x
### Visualized the data
plot(y~x)
xy.lo <- data.frame(x = seq(min(x),max(x),len = 100), y = predict(loess(y~x),data.frame(x=seq(min(x),max(x),len = 100))))
lines(xy.lo)
### See roughly where the loess thinks the bottom of the
### parabola.
round(min(xy.lo$y))
round(x[which.min(y)])
#### Modeling the data ----
### let's transform the variables
yp <- y - 4
xp <- x - 2
### now plot the variables
### why is using abs() justified?
plot(abs(yp)~abs(xp),log="xy")
### let's try our linear model
m3 <- lm(log(abs(yp))~log(abs(xp)))
### That model had an intercept, which we don't want.
### Run the model again without an intercept.
m4 <- lm(log(abs(yp))~log(abs(xp))-1)
### Now check out the diagnostics
plot(m4)
par(mfrow=c(2,2))
### Now check out the diagnostics
plot(m4)
