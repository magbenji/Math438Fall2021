py_install("scikit-learn")
reticulate::repl_python()
py_install("statsmodels")
reticulate::repl_python()
py_install("matplotlib")
py_config()
reticulate::repl_python()
getwd()
data <- read.csv("Observations.csv", header = T)
#### Plot the data ---------
### Let's explore the data visually
plot(data, type="l")
### Data seem to be exponential of some kind
### Try plotting log y
plot(data,type="l", log="y")
### Log y didn't fix it. Try log x instead.
plot(data,type="l", log="x")
### Log x and log y didn't work. Try log-log instead.
plot(data,type="l", log="xy")
### What model does this suggest in the untransformed variables x,y?
#### Creating a basic model -----
### That produced a nice line!
### Let's transform the data
tdata <- log(data)
### Fit the model
summary(m <- lm(Observation ~ Input, tdata))
### Write down the model for the untransformed variables!
exp(coef(m)[1])
#### A slightly different model ----
### We can also fit this using a altered "link" function in glm, try it!
summary(m2 <- glm(Observation ~ log(Input), data, family = gaussian(link = "log")))
#Compare the predictions of the 2 models
plot(predict(m2), predict(m))
abline(a=0,b=1) #add a 1-to-1 line for convenience
#### Comparing models ----
### Let's choose between the models and compare coefficients
AIC(m,m2)
coef(m)
coef(m2)
anova(m1,m2)
anova(m,m2)
summary(anova(m,m2))
summary(aov(m,m2))
aov(m,m2)
predict(m)
(exp(predict(m)) - data$Observation)^2
sum(exp(predict(m)) - data$Observation)^2)
sum((exp(predict(m)) - data$Observation)^2)
predict(m2)
predict(m2, type="response")
sum((predict(m2, type="response") -  data$Observation)^2)
m2$residuals
sum(m2$residuals)^2
reticulate::repl_python()
set.seed(julian(Sys.Date()))
x <- runif(100,0,10)
x
reticulate::repl_python()
y <- 4 + (x-2)^2 + runif(100,-1,1)*0.5*x
### Visualized the data
plot(y~x)
xy.lo <- data.frame(x = seq(min(x),max(x),len = 100), y = predict(loess(y~x),data.frame(x=seq(min(x),max(x),len = 100))))
lines(xy.lo)
reticulate::repl_python()
round(min(xy.lo$y))
round(x[which.min(y)])
#### Modeling the data ----
### let's transform the variables
yp <- y - 4
xp <- x - 2
### now plot the variables
### why is using abs() justified?
plot(abs(yp)~abs(xp),log="xy")
### let's try our linear model
reticulate::repl_python()
library(reticulate)
py_install("statsmodels")
reticulate::repl_python()
py_config()
py_install("statmodels")
py_install("statsmodels")
reticulate::repl_python()
bob <- 42
reticulate::repl_python()
py_run_string("bob = 42")
py$results2
py$results2
